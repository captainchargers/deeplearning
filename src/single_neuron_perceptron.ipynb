{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Neuron Perceptron\n",
    "Neural Network (a.k.a deep learning) is a set of layers, and the layers are set of neurons.  \n",
    "In order to understand how deep learning works,  \n",
    "understanding of single neuron (a.k.a node or perceptron) is very important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi Layer Perceptron (a.k.a MLP) which is basic model of deep learning works like below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image of Perceptron](https://www.ritchievink.com/img/post-9-mlp/nn_diagram_1.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neuron (a.k.a node, perceptron) works like below picture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image of Perceptron](https://i.stack.imgur.com/VqOpE.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are various activation functions used by many type of deep learnings,  \n",
    "Traditionally, Single Neuron Perceptron used step function as activation function.  \n",
    "Single Perceptron could solve AND, OR operation, but it couldn't solve XOR operation.\n",
    "XOR can be solved by Multi Layer Perceptron (MLP), even the MLP has perceptron in its name,  \n",
    "any activation function can be used for MLP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image of Perceptron](https://qph.ec.quoracdn.net/main-qimg-01c26eabd976b027e49015428b7fcf01?convert_to_webp=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice with Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants\n",
    "We will practice perceptron with AND, OR, XOR operation.  \n",
    "For Truth table and bias of the perceptron, we created constant here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 1.0\n",
    "F = 0.0\n",
    "bias = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Data\n",
    "Here is the truth table we will solve using perceptron.\n",
    "![Image of Perceptron](https://introcs.cs.princeton.edu/java/71boolean/images/truth-table.png)\n",
    "We will choose data for any operation from these functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_AND_data():\n",
    "    X = [\n",
    "    [F, F, bias],\n",
    "    [F, T, bias],\n",
    "    [T, F, bias],\n",
    "    [T, T, bias]\n",
    "    ]\n",
    "    \n",
    "    Y = [\n",
    "        [F],\n",
    "        [F],\n",
    "        [F],\n",
    "        [T]\n",
    "    ]\n",
    "    \n",
    "    return X, Y\n",
    "\n",
    "def get_OR_data():\n",
    "    X = [\n",
    "    [F, F, bias],\n",
    "    [F, T, bias],\n",
    "    [T, F, bias],\n",
    "    [T, T, bias]\n",
    "    ]\n",
    "    \n",
    "    Y = [\n",
    "        [F],\n",
    "        [T],\n",
    "        [T],\n",
    "        [T]\n",
    "    ]\n",
    "    \n",
    "    return X, Y\n",
    "\n",
    "def get_XOR_data():\n",
    "    X = [\n",
    "    [F, F, bias],\n",
    "    [F, T, bias],\n",
    "    [T, F, bias],\n",
    "    [T, T, bias]\n",
    "    ]\n",
    "    \n",
    "    Y = [\n",
    "        [F],\n",
    "        [T],\n",
    "        [T],\n",
    "        [F]\n",
    "    ]\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose data for your practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = get_AND_data()\n",
    "#X, Y = get_OR_data()\n",
    "#X, Y = get_XOR_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize weights\n",
    "We will initialize weight with random number.  \n",
    "since the truth table has two inputs with one bias,  \n",
    "and we just have single neuron, the shape of weight is [3,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_normal([3, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation Function\n",
    "Perceptron uses step function as its activation function.  \n",
    "step(x) = { 1 if x > 0; 0 otherwise }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(x):\n",
    "    return tf.to_float(tf.greater(x, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function\n",
    "We will simply use Mean Square Error as its loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = tf.matmul(X, W)\n",
    "output = step(f)\n",
    "error = tf.subtract(Y, output)\n",
    "mse = tf.reduce_mean(tf.square(error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize weights\n",
    "Here is how we update weights using unified learning rule which derived from below concept.  \n",
    "\n",
    "if target == 1 and activation == 0:  \n",
    "  w_new = w_old + input  \n",
    "  \n",
    "if target == 0 and activation == 1:  \n",
    "  w_new = w_old - input  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = tf.matmul(X, error, transpose_a=True)\n",
    "train = tf.assign(W, tf.add(W, delta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Testing\n",
    "Start Trainin and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 mse: 0.75\n",
      "epoch: 2 mse: 0.25\n",
      "epoch: 3 mse: 0.25\n",
      "epoch: 4 mse: 0.25\n",
      "epoch: 5 mse: 0.5\n",
      "epoch: 6 mse: 0.25\n",
      "epoch: 7 mse: 0.0\n",
      "\n",
      "Testing Result:\n",
      "[array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [1.]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "    err = 1\n",
    "    epoch, max_epochs = 0, 20\n",
    "    while err > 0.0 and epoch < max_epochs:\n",
    "        epoch += 1\n",
    "        err = sess.run(mse)\n",
    "        sess.run(train)\n",
    "        print('epoch:', epoch, 'mse:', err)\n",
    "        \n",
    "    print(\"\\nTesting Result:\")\n",
    "    print(sess.run([output]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## single perceptron only works on linearly separable classification\n",
    "One perceptron is one decision boundary, so it only solve linearly separable problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image of Perceptron](https://qph.fs.quoracdn.net/main-qimg-a6c557af4280d1f85cacc66e048e82f3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP (multi layer perceptron) with two neurons in hidden layer can solve XOR.  \n",
    "Two neurons in hidden layer will draw two boundary lines (z1, z2), \n",
    "\n",
    "we can make z1, z2 truth table like below,\n",
    "z1, z2, value\n",
    "0,  0,  0\n",
    "0,  1,  1\n",
    "1,  0,  1\n",
    "\n",
    "As you can see from below upper 2d chart, now it is linearly separable on z1, z2 axis,  \n",
    "one perceptron in the next layer can classify output from hidden layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image of Perceptron](http://cps0715.weebly.com/uploads/7/4/0/3/74035485/8009014_orig.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
